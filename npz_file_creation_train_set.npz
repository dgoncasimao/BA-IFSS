import os
import cv2
import numpy as np
import json
from scipy.ndimage import uniform_filter, gaussian_filter

# Paths
images_folder = './'  # Carpeta donde están las imágenes redimensionadas
masks_folder = './augmented_train_set/masks'  # Carpeta donde están las máscaras redimensionadas
output_npz_folder = './npz_files/augmented_train'  # Carpeta para guardar los archivos .npz
annotations_file = './videos_first_batch_json.json'

os.makedirs(output_npz_folder, exist_ok=True)  # Crear la carpeta de salida si no existe

original_height, original_width = 632, 508  # Resolución original
target_width, target_height = 512, 512  # Resolución después de resizing

scale = min(target_width / original_width, target_height / original_height)
new_width = int(original_width * scale)
new_height = int(original_height * scale)

pad_x = (target_width - new_width) // 2  # Padding en los bordes laterales
pad_y = 0  # Padding en los bordes superior e inferior

# Función sigmoide para transformar en mapas de probabilidad
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Función para normalizar al rango [0, 1]
def normalize_minmax(x):
    return x.astype(np.float32) / 255.0

# Función para normalizar usando z-score
def normalize_zscore(x):
    mean = np.mean(x)
    std = np.std(x)
    # Evitar división por cero
    return (x - mean) / (std + 1e-8)

# Función para normalización logarítmica
def normalize_log(x):
    return np.log1p(x.astype(np.float32))  # log(1 + x) para evitar log(0)

# Función para normalización por recorte de percentiles
def normalize_clipping(x, lower_percentile=1, upper_percentile=99):
    lower = np.percentile(x, lower_percentile)
    upper = np.percentile(x, upper_percentile)
    x_clipped = np.clip(x, lower, upper)
    return (x_clipped - lower) / (upper - lower + 1e-8)

# Función para Local Contrast Normalization (LCN)
def normalize_local_contrast(x, filter_size=15):
    local_mean = uniform_filter(x, size=filter_size)
    local_std = np.sqrt(uniform_filter(x**2, size=filter_size) - local_mean**2)
    return (x - local_mean) / (local_std + 1e-8).astype(np.float32)



# Contador global para nombres de archivos
frame_counter = 1

# Parámetro para elegir el tipo de normalización ('minmax', 'zscore', 'log', 'clipping', 'local_contrast', 'none')
normalization_type = "zscore"  # Cambiar a otro método según sea necesario

# Iterar por cada archivo en la carpeta de imágenes
for image_name in os.listdir(images_folder):
    image_path = os.path.join(images_folder, image_name)

    if "_mask" in image_name:
        mask_name = image_name  # Si ya tiene "_mask", no cambiar nada
    elif "_aug" in image_name:  # Si es una imagen aumentada
        mask_name = image_name.replace(".png", "_mask.png").replace(".jpg", "_mask.png")
    else:  # Si es una imagen original
        mask_name = image_name.replace(".png", "_mask.png").replace(".jpg", "_mask.png")

    mask_path = os.path.join(masks_folder, mask_name)

    # Verificar que ambos archivos existan
    if not os.path.isfile(image_path):
        print(f"Falta la imagen: {image_path}")
        continue
    if not os.path.isfile(mask_path):
        print(f"Falta la máscara: {mask_path}")
        continue

    # Leer la imagen y la máscara
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Leer en escala de grises
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Leer en escala de grises

    if image is None:
        print(f"No se pudo leer la imagen: {image_path}")
        continue
    if mask is None:
        print(f"No se pudo leer la máscara: {mask_path}")
        continue

    # Normalizar las imágenes según el método elegido
    if normalization_type == "minmax":
        image = normalize_minmax(image)
        mask = normalize_minmax(mask)
    elif normalization_type == "zscore":
        image = normalize_zscore(image)
        mask = normalize_zscore(mask)
    elif normalization_type == "log":
        image = normalize_log(image)
        mask = normalize_log(mask)
    elif normalization_type == "clipping":
        image = normalize_clipping(image)
        mask = normalize_clipping(mask)
    elif normalization_type == "local_contrast":
        image = normalize_local_contrast(image)
        mask = normalize_local_contrast(mask)
    elif normalization_type == "none":
        image = image.astype(np.float32)
        mask = mask.astype(np.float32)
    else:
        print(f"Tipo de normalización desconocido: {normalization_type}")
        break

    frame_key = frame_key = image_name.replace(".jpg", "")
    scaled_coords = coords_dict.get(frame_key, np.array([]))
    # Transformar en mapas de probabilidad (opcional)
    #image_prob = sigmoid(image)  # Aplicar sigmoide a la imagen
    #mask_prob = sigmoid(mask)    # Aplicar sigmoide a la máscara

    # Generar un nombre único para cada archivo .npz en formato frame_0001, frame_0002, etc.
    output_npz_name = f"frame_{frame_counter:04d}.npz"
    output_npz_path = os.path.join(output_npz_folder, output_npz_name)

    # Guardar el archivo .npz con claves "image" y "label"

    #print("Ejemplo de frame_key en coords_dict:", list(coords_dict.keys())[:5])  # Claves en coords_dict
    #print("Ejemplo de nombres de imágenes:", os.listdir(images_folder)[:5])  # Nombres de archivos en images_folder


    try:
        np.savez_compressed(output_npz_path, image=image, label=mask, insertion_coords=scaled_coords)  # Agregar _prob
        print(f"Archivo guardado: {output_npz_name}")
    except Exception as e:
        print(f"Error al guardar el archivo {output_npz_name}: {e}")
        continue

    # Incrementar el contador
    frame_counter += 1

print("Proceso completado.")

data = np.load("./npz_files/train/frame_0001.npz")
print("Imagen shape:", data["image"].shape)
print("Máscara shape:", data["label"].shape)
print("Coordenadas escaladas:", data["insertion_coords"])




