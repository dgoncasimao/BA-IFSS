{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16-UNet with DL-Kfold (build_vgg16_unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of aponeurosis images =  890\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dministrator/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8880 - io_u: 0.0968 - loss: 0.3973\n",
      "Epoch 1: val_loss improved from inf to 0.17054, saving model to K-foldno1-VGG16-V1-VL-BFRHL-256.keras\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.8881 - io_u: 0.0972 - loss: 0.3966 - val_accuracy: 0.9420 - val_io_u: 0.1830 - val_loss: 0.1705 - learning_rate: 1.0000e-05\n",
      "Epoch 2/100\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9296 - io_u: 0.3617 - loss: 0.1156\n",
      "Epoch 2: val_loss improved from 0.17054 to 0.10485, saving model to K-foldno1-VGG16-V1-VL-BFRHL-256.keras\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.9296 - io_u: 0.3618 - loss: 0.1155 - val_accuracy: 0.9486 - val_io_u: 0.2845 - val_loss: 0.1048 - learning_rate: 1.0000e-05\n",
      "Epoch 3/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9331 - io_u: 0.4689 - loss: 0.0747\n",
      "Epoch 3: val_loss improved from 0.10485 to 0.08461, saving model to K-foldno1-VGG16-V1-VL-BFRHL-256.keras\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 46ms/step - accuracy: 0.9331 - io_u: 0.4691 - loss: 0.0747 - val_accuracy: 0.9516 - val_io_u: 0.3268 - val_loss: 0.0846 - learning_rate: 1.0000e-05\n",
      "Epoch 4/100\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9341 - io_u: 0.5317 - loss: 0.0579\n",
      "Epoch 4: val_loss did not improve from 0.08461\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9341 - io_u: 0.5318 - loss: 0.0579 - val_accuracy: 0.9491 - val_io_u: 0.3734 - val_loss: 0.0861 - learning_rate: 1.0000e-05\n",
      "Epoch 5/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9348 - io_u: 0.5688 - loss: 0.0496\n",
      "Epoch 5: val_loss improved from 0.08461 to 0.06900, saving model to K-foldno1-VGG16-V1-VL-BFRHL-256.keras\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.9348 - io_u: 0.5689 - loss: 0.0496 - val_accuracy: 0.9508 - val_io_u: 0.4122 - val_loss: 0.0690 - learning_rate: 1.0000e-05\n",
      "Epoch 6/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9338 - io_u: 0.6076 - loss: 0.0438\n",
      "Epoch 6: val_loss improved from 0.06900 to 0.06327, saving model to K-foldno1-VGG16-V1-VL-BFRHL-256.keras\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.9338 - io_u: 0.6077 - loss: 0.0438 - val_accuracy: 0.9518 - val_io_u: 0.4315 - val_loss: 0.0633 - learning_rate: 1.0000e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9334 - io_u: 0.6337 - loss: 0.0398\n",
      "Epoch 7: val_loss did not improve from 0.06327\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9334 - io_u: 0.6337 - loss: 0.0398 - val_accuracy: 0.9514 - val_io_u: 0.4265 - val_loss: 0.0681 - learning_rate: 1.0000e-05\n",
      "Epoch 8/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9335 - io_u: 0.6601 - loss: 0.0357\n",
      "Epoch 8: val_loss did not improve from 0.06327\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9335 - io_u: 0.6601 - loss: 0.0357 - val_accuracy: 0.9411 - val_io_u: 0.4616 - val_loss: 0.1346 - learning_rate: 1.0000e-05\n",
      "Epoch 9/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9314 - io_u: 0.6685 - loss: 0.0378\n",
      "Epoch 9: val_loss improved from 0.06327 to 0.06310, saving model to K-foldno1-VGG16-V1-VL-BFRHL-256.keras\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.9314 - io_u: 0.6686 - loss: 0.0378 - val_accuracy: 0.9520 - val_io_u: 0.4523 - val_loss: 0.0631 - learning_rate: 1.0000e-05\n",
      "Epoch 10/100\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9333 - io_u: 0.7000 - loss: 0.0306\n",
      "Epoch 10: val_loss improved from 0.06310 to 0.05987, saving model to K-foldno1-VGG16-V1-VL-BFRHL-256.keras\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 47ms/step - accuracy: 0.9333 - io_u: 0.7000 - loss: 0.0306 - val_accuracy: 0.9509 - val_io_u: 0.5003 - val_loss: 0.0599 - learning_rate: 1.0000e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9330 - io_u: 0.7184 - loss: 0.0282\n",
      "Epoch 11: val_loss did not improve from 0.05987\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9330 - io_u: 0.7184 - loss: 0.0282 - val_accuracy: 0.9506 - val_io_u: 0.4930 - val_loss: 0.0649 - learning_rate: 1.0000e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9323 - io_u: 0.7379 - loss: 0.0267\n",
      "Epoch 12: val_loss improved from 0.05987 to 0.05985, saving model to K-foldno1-VGG16-V1-VL-BFRHL-256.keras\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.9323 - io_u: 0.7378 - loss: 0.0267 - val_accuracy: 0.9511 - val_io_u: 0.5060 - val_loss: 0.0598 - learning_rate: 1.0000e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9351 - io_u: 0.7422 - loss: 0.0246\n",
      "Epoch 13: val_loss did not improve from 0.05985\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9351 - io_u: 0.7423 - loss: 0.0246 - val_accuracy: 0.9506 - val_io_u: 0.5113 - val_loss: 0.0632 - learning_rate: 1.0000e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9353 - io_u: 0.7597 - loss: 0.0229\n",
      "Epoch 14: val_loss improved from 0.05985 to 0.05807, saving model to K-foldno1-VGG16-V1-VL-BFRHL-256.keras\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.9352 - io_u: 0.7598 - loss: 0.0229 - val_accuracy: 0.9513 - val_io_u: 0.5359 - val_loss: 0.0581 - learning_rate: 1.0000e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9337 - io_u: 0.7782 - loss: 0.0215\n",
      "Epoch 15: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9337 - io_u: 0.7782 - loss: 0.0215 - val_accuracy: 0.9493 - val_io_u: 0.5370 - val_loss: 0.0690 - learning_rate: 1.0000e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9328 - io_u: 0.7968 - loss: 0.0201\n",
      "Epoch 16: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9328 - io_u: 0.7968 - loss: 0.0201 - val_accuracy: 0.9489 - val_io_u: 0.5574 - val_loss: 0.0668 - learning_rate: 1.0000e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9333 - io_u: 0.8021 - loss: 0.0191\n",
      "Epoch 17: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9333 - io_u: 0.8021 - loss: 0.0191 - val_accuracy: 0.9505 - val_io_u: 0.5426 - val_loss: 0.0664 - learning_rate: 1.0000e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9333 - io_u: 0.8174 - loss: 0.0179\n",
      "Epoch 18: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9333 - io_u: 0.8174 - loss: 0.0179 - val_accuracy: 0.9500 - val_io_u: 0.5798 - val_loss: 0.0647 - learning_rate: 1.0000e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9342 - io_u: 0.8240 - loss: 0.0168\n",
      "Epoch 19: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9342 - io_u: 0.8241 - loss: 0.0168 - val_accuracy: 0.9492 - val_io_u: 0.5581 - val_loss: 0.0737 - learning_rate: 1.0000e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9334 - io_u: 0.8392 - loss: 0.0159\n",
      "Epoch 20: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9334 - io_u: 0.8392 - loss: 0.0159 - val_accuracy: 0.9491 - val_io_u: 0.5741 - val_loss: 0.0694 - learning_rate: 1.0000e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9335 - io_u: 0.8490 - loss: 0.0150\n",
      "Epoch 21: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9335 - io_u: 0.8490 - loss: 0.0150 - val_accuracy: 0.9503 - val_io_u: 0.5684 - val_loss: 0.0706 - learning_rate: 1.0000e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9332 - io_u: 0.8589 - loss: 0.0142\n",
      "Epoch 22: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9332 - io_u: 0.8589 - loss: 0.0142 - val_accuracy: 0.9500 - val_io_u: 0.5700 - val_loss: 0.0727 - learning_rate: 1.0000e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9336 - io_u: 0.8648 - loss: 0.0136\n",
      "Epoch 23: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9336 - io_u: 0.8648 - loss: 0.0136 - val_accuracy: 0.9496 - val_io_u: 0.6091 - val_loss: 0.0701 - learning_rate: 1.0000e-05\n",
      "Epoch 24/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9355 - io_u: 0.8696 - loss: 0.0130\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9354 - io_u: 0.8696 - loss: 0.0130 - val_accuracy: 0.9492 - val_io_u: 0.6125 - val_loss: 0.0684 - learning_rate: 1.0000e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9344 - io_u: 0.8750 - loss: 0.0122\n",
      "Epoch 25: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9344 - io_u: 0.8750 - loss: 0.0122 - val_accuracy: 0.9501 - val_io_u: 0.6080 - val_loss: 0.0676 - learning_rate: 1.0000e-06\n",
      "Epoch 26/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9344 - io_u: 0.8824 - loss: 0.0117\n",
      "Epoch 26: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9344 - io_u: 0.8824 - loss: 0.0117 - val_accuracy: 0.9501 - val_io_u: 0.6102 - val_loss: 0.0685 - learning_rate: 1.0000e-06\n",
      "Epoch 27/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9343 - io_u: 0.8846 - loss: 0.0115\n",
      "Epoch 27: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9343 - io_u: 0.8846 - loss: 0.0115 - val_accuracy: 0.9499 - val_io_u: 0.6035 - val_loss: 0.0703 - learning_rate: 1.0000e-06\n",
      "Epoch 28/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9330 - io_u: 0.8865 - loss: 0.0115\n",
      "Epoch 28: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9330 - io_u: 0.8865 - loss: 0.0115 - val_accuracy: 0.9500 - val_io_u: 0.6152 - val_loss: 0.0701 - learning_rate: 1.0000e-06\n",
      "Epoch 29/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9333 - io_u: 0.8864 - loss: 0.0114\n",
      "Epoch 29: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9333 - io_u: 0.8864 - loss: 0.0114 - val_accuracy: 0.9498 - val_io_u: 0.6143 - val_loss: 0.0714 - learning_rate: 1.0000e-06\n",
      "Epoch 30/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9347 - io_u: 0.8869 - loss: 0.0112\n",
      "Epoch 30: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9347 - io_u: 0.8869 - loss: 0.0112 - val_accuracy: 0.9498 - val_io_u: 0.6160 - val_loss: 0.0720 - learning_rate: 1.0000e-06\n",
      "Epoch 31/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9337 - io_u: 0.8889 - loss: 0.0112\n",
      "Epoch 31: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9337 - io_u: 0.8889 - loss: 0.0112 - val_accuracy: 0.9497 - val_io_u: 0.6142 - val_loss: 0.0736 - learning_rate: 1.0000e-06\n",
      "Epoch 32/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9343 - io_u: 0.8885 - loss: 0.0110\n",
      "Epoch 32: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9343 - io_u: 0.8885 - loss: 0.0110 - val_accuracy: 0.9499 - val_io_u: 0.6131 - val_loss: 0.0728 - learning_rate: 1.0000e-06\n",
      "Epoch 33/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9342 - io_u: 0.8906 - loss: 0.0110\n",
      "Epoch 33: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9342 - io_u: 0.8906 - loss: 0.0110 - val_accuracy: 0.9496 - val_io_u: 0.6096 - val_loss: 0.0752 - learning_rate: 1.0000e-06\n",
      "Epoch 34/100\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9327 - io_u: 0.8933 - loss: 0.0109\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9327 - io_u: 0.8933 - loss: 0.0109 - val_accuracy: 0.9497 - val_io_u: 0.6117 - val_loss: 0.0754 - learning_rate: 1.0000e-06\n",
      "Epoch 34: early stopping\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9330 - io_u: 0.8958 - loss: 0.0108\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9330 - io_u: 0.8958 - loss: 0.0108 - val_accuracy: 0.9497 - val_io_u: 0.6050 - val_loss: 0.0757 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9337 - io_u: 0.8927 - loss: 0.0109\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9337 - io_u: 0.8927 - loss: 0.0109 - val_accuracy: 0.9497 - val_io_u: 0.6175 - val_loss: 0.0756 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9324 - io_u: 0.8967 - loss: 0.0108\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9324 - io_u: 0.8966 - loss: 0.0108 - val_accuracy: 0.9497 - val_io_u: 0.6105 - val_loss: 0.0762 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9343 - io_u: 0.8940 - loss: 0.0107\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9343 - io_u: 0.8940 - loss: 0.0107 - val_accuracy: 0.9497 - val_io_u: 0.6124 - val_loss: 0.0752 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9342 - io_u: 0.8936 - loss: 0.0107\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9342 - io_u: 0.8936 - loss: 0.0107 - val_accuracy: 0.9497 - val_io_u: 0.6165 - val_loss: 0.0754 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9332 - io_u: 0.8968 - loss: 0.0107\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9332 - io_u: 0.8967 - loss: 0.0107 - val_accuracy: 0.9497 - val_io_u: 0.6065 - val_loss: 0.0758 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9332 - io_u: 0.8963 - loss: 0.0107\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9333 - io_u: 0.8963 - loss: 0.0107 - val_accuracy: 0.9498 - val_io_u: 0.6147 - val_loss: 0.0759 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9348 - io_u: 0.8921 - loss: 0.0107\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9348 - io_u: 0.8921 - loss: 0.0107 - val_accuracy: 0.9497 - val_io_u: 0.6131 - val_loss: 0.0764 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9338 - io_u: 0.8933 - loss: 0.0107\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9338 - io_u: 0.8933 - loss: 0.0107 - val_accuracy: 0.9497 - val_io_u: 0.6180 - val_loss: 0.0763 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9334 - io_u: 0.8981 - loss: 0.0107\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9334 - io_u: 0.8981 - loss: 0.0107 - val_accuracy: 0.9497 - val_io_u: 0.6073 - val_loss: 0.0766 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9339 - io_u: 0.8911 - loss: 0.0108\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9339 - io_u: 0.8911 - loss: 0.0108 - val_accuracy: 0.9497 - val_io_u: 0.6104 - val_loss: 0.0763 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9352 - io_u: 0.8945 - loss: 0.0106\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9352 - io_u: 0.8945 - loss: 0.0106 - val_accuracy: 0.9497 - val_io_u: 0.6111 - val_loss: 0.0766 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9347 - io_u: 0.8947 - loss: 0.0106\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9347 - io_u: 0.8947 - loss: 0.0106 - val_accuracy: 0.9496 - val_io_u: 0.6160 - val_loss: 0.0763 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9345 - io_u: 0.8909 - loss: 0.0107\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9345 - io_u: 0.8909 - loss: 0.0107 - val_accuracy: 0.9496 - val_io_u: 0.6209 - val_loss: 0.0767 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9336 - io_u: 0.8935 - loss: 0.0107\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9336 - io_u: 0.8935 - loss: 0.0107 - val_accuracy: 0.9497 - val_io_u: 0.6116 - val_loss: 0.0765 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9338 - io_u: 0.8951 - loss: 0.0107\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9338 - io_u: 0.8951 - loss: 0.0107 - val_accuracy: 0.9497 - val_io_u: 0.6125 - val_loss: 0.0766 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9348 - io_u: 0.8936 - loss: 0.0106\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9348 - io_u: 0.8936 - loss: 0.0106 - val_accuracy: 0.9497 - val_io_u: 0.6109 - val_loss: 0.0761 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9336 - io_u: 0.8964 - loss: 0.0106\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9336 - io_u: 0.8964 - loss: 0.0106 - val_accuracy: 0.9497 - val_io_u: 0.6087 - val_loss: 0.0768 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9352 - io_u: 0.8924 - loss: 0.0106\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9352 - io_u: 0.8924 - loss: 0.0106 - val_accuracy: 0.9496 - val_io_u: 0.6017 - val_loss: 0.0767 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9341 - io_u: 0.8955 - loss: 0.0106\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9341 - io_u: 0.8955 - loss: 0.0106 - val_accuracy: 0.9497 - val_io_u: 0.6153 - val_loss: 0.0764 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9337 - io_u: 0.8968 - loss: 0.0106\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.9337 - io_u: 0.8968 - loss: 0.0106 - val_accuracy: 0.9497 - val_io_u: 0.6103 - val_loss: 0.0769 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9350 - io_u: 0.8955 - loss: 0.0105\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.9350 - io_u: 0.8955 - loss: 0.0105 - val_accuracy: 0.9497 - val_io_u: 0.6095 - val_loss: 0.0767 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9337 - io_u: 0.8955 - loss: 0.0106\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.9337 - io_u: 0.8955 - loss: 0.0106 - val_accuracy: 0.9496 - val_io_u: 0.6131 - val_loss: 0.0775 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9360 - io_u: 0.8927 - loss: 0.0105\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.9360 - io_u: 0.8927 - loss: 0.0105 - val_accuracy: 0.9497 - val_io_u: 0.6045 - val_loss: 0.0765 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9324 - io_u: 0.9006 - loss: 0.0106\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.9324 - io_u: 0.9006 - loss: 0.0106 - val_accuracy: 0.9496 - val_io_u: 0.6155 - val_loss: 0.0781 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9347 - io_u: 0.8961 - loss: 0.0105\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.9347 - io_u: 0.8961 - loss: 0.0105 - val_accuracy: 0.9497 - val_io_u: 0.6150 - val_loss: 0.0772 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9333 - io_u: 0.8973 - loss: 0.0106\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.9333 - io_u: 0.8973 - loss: 0.0106 - val_accuracy: 0.9497 - val_io_u: 0.6079 - val_loss: 0.0779 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9353 - io_u: 0.8927 - loss: 0.0105\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9353 - io_u: 0.8927 - loss: 0.0105 - val_accuracy: 0.9496 - val_io_u: 0.6161 - val_loss: 0.0776 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9334 - io_u: 0.8976 - loss: 0.0106\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9334 - io_u: 0.8976 - loss: 0.0106 - val_accuracy: 0.9497 - val_io_u: 0.6193 - val_loss: 0.0776 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9347 - io_u: 0.8945 - loss: 0.0105\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9347 - io_u: 0.8945 - loss: 0.0105 - val_accuracy: 0.9496 - val_io_u: 0.6155 - val_loss: 0.0774 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9326 - io_u: 0.8993 - loss: 0.0105\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9327 - io_u: 0.8992 - loss: 0.0105 - val_accuracy: 0.9497 - val_io_u: 0.6102 - val_loss: 0.0782 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9339 - io_u: 0.8971 - loss: 0.0105\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9339 - io_u: 0.8971 - loss: 0.0105 - val_accuracy: 0.9497 - val_io_u: 0.6135 - val_loss: 0.0780 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9337 - io_u: 0.8992 - loss: 0.0105\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9337 - io_u: 0.8992 - loss: 0.0105 - val_accuracy: 0.9496 - val_io_u: 0.6189 - val_loss: 0.0778 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9326 - io_u: 0.9021 - loss: 0.0105\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9326 - io_u: 0.9021 - loss: 0.0105 - val_accuracy: 0.9496 - val_io_u: 0.6127 - val_loss: 0.0781 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9336 - io_u: 0.8982 - loss: 0.0105\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9336 - io_u: 0.8982 - loss: 0.0105 - val_accuracy: 0.9497 - val_io_u: 0.6149 - val_loss: 0.0777 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9343 - io_u: 0.8989 - loss: 0.0104\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9343 - io_u: 0.8989 - loss: 0.0104 - val_accuracy: 0.9496 - val_io_u: 0.6153 - val_loss: 0.0782 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9324 - io_u: 0.9007 - loss: 0.0105\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9324 - io_u: 0.9007 - loss: 0.0105 - val_accuracy: 0.9496 - val_io_u: 0.6102 - val_loss: 0.0785 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9331 - io_u: 0.9017 - loss: 0.0105\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9331 - io_u: 0.9017 - loss: 0.0105 - val_accuracy: 0.9496 - val_io_u: 0.6232 - val_loss: 0.0782 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9338 - io_u: 0.8990 - loss: 0.0104\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9338 - io_u: 0.8990 - loss: 0.0104 - val_accuracy: 0.9496 - val_io_u: 0.6062 - val_loss: 0.0783 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9350 - io_u: 0.8964 - loss: 0.0104\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9350 - io_u: 0.8964 - loss: 0.0104 - val_accuracy: 0.9496 - val_io_u: 0.6141 - val_loss: 0.0781 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9342 - io_u: 0.8967 - loss: 0.0105\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9342 - io_u: 0.8967 - loss: 0.0105 - val_accuracy: 0.9496 - val_io_u: 0.6084 - val_loss: 0.0790 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9344 - io_u: 0.8979 - loss: 0.0104\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9344 - io_u: 0.8979 - loss: 0.0104 - val_accuracy: 0.9496 - val_io_u: 0.6127 - val_loss: 0.0783 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9358 - io_u: 0.8919 - loss: 0.0104\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9358 - io_u: 0.8919 - loss: 0.0104 - val_accuracy: 0.9496 - val_io_u: 0.6193 - val_loss: 0.0784 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9348 - io_u: 0.8969 - loss: 0.0104\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9348 - io_u: 0.8969 - loss: 0.0104 - val_accuracy: 0.9496 - val_io_u: 0.6076 - val_loss: 0.0784 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9339 - io_u: 0.8976 - loss: 0.0104\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9339 - io_u: 0.8976 - loss: 0.0104 - val_accuracy: 0.9496 - val_io_u: 0.6133 - val_loss: 0.0783 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9335 - io_u: 0.9002 - loss: 0.0104\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9335 - io_u: 0.9002 - loss: 0.0104 - val_accuracy: 0.9496 - val_io_u: 0.6161 - val_loss: 0.0791 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9344 - io_u: 0.8988 - loss: 0.0103\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9344 - io_u: 0.8988 - loss: 0.0103 - val_accuracy: 0.9496 - val_io_u: 0.6199 - val_loss: 0.0784 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9344 - io_u: 0.8988 - loss: 0.0104\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9344 - io_u: 0.8988 - loss: 0.0104 - val_accuracy: 0.9496 - val_io_u: 0.6108 - val_loss: 0.0792 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9339 - io_u: 0.9008 - loss: 0.0104\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9339 - io_u: 0.9008 - loss: 0.0104 - val_accuracy: 0.9496 - val_io_u: 0.6185 - val_loss: 0.0794 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9344 - io_u: 0.9005 - loss: 0.0103\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9344 - io_u: 0.9005 - loss: 0.0103 - val_accuracy: 0.9496 - val_io_u: 0.6102 - val_loss: 0.0792 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9339 - io_u: 0.8994 - loss: 0.0103\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9339 - io_u: 0.8994 - loss: 0.0103 - val_accuracy: 0.9496 - val_io_u: 0.6091 - val_loss: 0.0791 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9334 - io_u: 0.8968 - loss: 0.0104\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9334 - io_u: 0.8968 - loss: 0.0104 - val_accuracy: 0.9496 - val_io_u: 0.6201 - val_loss: 0.0792 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9340 - io_u: 0.8977 - loss: 0.0103\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9340 - io_u: 0.8977 - loss: 0.0103 - val_accuracy: 0.9496 - val_io_u: 0.6130 - val_loss: 0.0795 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9342 - io_u: 0.8987 - loss: 0.0103\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9342 - io_u: 0.8987 - loss: 0.0103 - val_accuracy: 0.9496 - val_io_u: 0.6188 - val_loss: 0.0793 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9350 - io_u: 0.8982 - loss: 0.0103\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9350 - io_u: 0.8982 - loss: 0.0103 - val_accuracy: 0.9496 - val_io_u: 0.6011 - val_loss: 0.0793 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9334 - io_u: 0.8996 - loss: 0.0103\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9334 - io_u: 0.8996 - loss: 0.0103 - val_accuracy: 0.9496 - val_io_u: 0.6134 - val_loss: 0.0794 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9348 - io_u: 0.8984 - loss: 0.0103\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9348 - io_u: 0.8984 - loss: 0.0103 - val_accuracy: 0.9496 - val_io_u: 0.6132 - val_loss: 0.0790 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9340 - io_u: 0.9027 - loss: 0.0103\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9340 - io_u: 0.9027 - loss: 0.0103 - val_accuracy: 0.9496 - val_io_u: 0.6026 - val_loss: 0.0789 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9338 - io_u: 0.9006 - loss: 0.0103\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9338 - io_u: 0.9006 - loss: 0.0103 - val_accuracy: 0.9495 - val_io_u: 0.6147 - val_loss: 0.0801 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9341 - io_u: 0.9005 - loss: 0.0103\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9341 - io_u: 0.9005 - loss: 0.0103 - val_accuracy: 0.9496 - val_io_u: 0.6089 - val_loss: 0.0798 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9332 - io_u: 0.9020 - loss: 0.0103\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9332 - io_u: 0.9020 - loss: 0.0103 - val_accuracy: 0.9496 - val_io_u: 0.6111 - val_loss: 0.0805 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9346 - io_u: 0.9004 - loss: 0.0102\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9346 - io_u: 0.9004 - loss: 0.0102 - val_accuracy: 0.9495 - val_io_u: 0.6204 - val_loss: 0.0799 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9331 - io_u: 0.9025 - loss: 0.0103\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9331 - io_u: 0.9025 - loss: 0.0103 - val_accuracy: 0.9496 - val_io_u: 0.6207 - val_loss: 0.0796 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9335 - io_u: 0.9038 - loss: 0.0102\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9335 - io_u: 0.9038 - loss: 0.0102 - val_accuracy: 0.9496 - val_io_u: 0.6074 - val_loss: 0.0800 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9348 - io_u: 0.8992 - loss: 0.0102\n",
      "Epoch 1: val_loss did not improve from 0.05807\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.9348 - io_u: 0.8992 - loss: 0.0102 - val_accuracy: 0.9496 - val_io_u: 0.6129 - val_loss: 0.0797 - learning_rate: 1.0000e-07\n",
      "\u001b[1m355/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9343 - io_u: 0.9023 - loss: 0.0102"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 238\u001b[0m\n\u001b[1;32m    235\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_generator, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m    236\u001b[0m                     callbacks\u001b[38;5;241m=\u001b[39mcallbacks, validation_data\u001b[38;5;241m=\u001b[39mval_generator)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m--> 238\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Train one epoch at a time to log metrics continuously\u001b[39;49;00m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# Extract metrics from history\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;66;03m#logs = {\u001b[39;00m\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;66;03m#\"epoch\": epoch + 1,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m#wandb.watch(model, log=\"all\", log_freq=10)\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# Increase fold number\u001b[39;00m\n\u001b[1;32m    261\u001b[0m fold_no \u001b[38;5;241m=\u001b[39m fold_no \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:395\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[1;32m    386\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m    387\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    394\u001b[0m     )\n\u001b[0;32m--> 395\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    407\u001b[0m }\n\u001b[1;32m    408\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:484\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    483\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m--> 484\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(step, logs)\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_evaluating:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m     iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m ):\n\u001b[1;32m    219\u001b[0m     opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mget_value()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001b[0m, in \u001b[0;36m_OptionalImpl.has_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_optional_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional_has_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001b[0m, in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOptionalHasValue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K, mixed_precision\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Model\n",
    "from keras_unet_collection.losses import focal_tversky\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.applications import VGG16 \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from wandb.integration.keras import WandbCallback\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "import wandb\n",
    "wandb.init(\n",
    "    project=\"VGG\"\n",
    ")\n",
    "wandb_callback = WandbCallback(\n",
    "    save_graph=True,\n",
    ")\n",
    "\n",
    "def IoU(y_true, y_pred, dtype=tf.float32):\n",
    "    y_pred = tf.cast(y_pred, dtype)\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "\n",
    "    y_pred = tf.squeeze(y_pred)\n",
    "    y_true = tf.squeeze(y_true)\n",
    "    \n",
    "    y_true_pos = tf.reshape(y_true, [-1])\n",
    "    y_pred_pos = tf.reshape(y_pred, [-1])\n",
    "\n",
    "    area_intersect = tf.reduce_sum(tf.multiply(y_true_pos, y_pred_pos))\n",
    "    \n",
    "    area_true = tf.reduce_sum(y_true_pos)\n",
    "    area_pred = tf.reduce_sum(y_pred_pos)\n",
    "    area_union = area_true + area_pred - area_intersect\n",
    "    \n",
    "    # Return the IoU score\n",
    "    return tf.math.divide_no_nan(area_intersect, area_union)\n",
    "\n",
    "def dice_score(y_true, y_pred, smooth=1):\n",
    "    \n",
    "    # Flatten\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def tversky(y_true, y_pred, smooth=1, alpha=0.7):\n",
    "    y_true_pos = K.flatten(y_true)\n",
    "    y_pred_pos = K.flatten(y_pred)\n",
    "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n",
    "    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n",
    "    return (true_pos + smooth) / (true_pos + alpha * false_neg + (1 - alpha) * false_pos + smooth)\n",
    "\n",
    "\n",
    "def tversky_loss(y_true, y_pred):\n",
    "    return 1 - tversky(y_true, y_pred)\n",
    "\n",
    "\n",
    "def focal_tversky_loss(y_true, y_pred, gamma=0.75):\n",
    "    tv = tversky(y_true, y_pred)\n",
    "    return K.pow((1 - tv), gamma)\n",
    "\n",
    "\n",
    "# Plot sample of model prediction\n",
    "def plot_sample(X, y, preds, binary_preds, ix=None):\n",
    "    if ix is None:\n",
    "        ix = random.randint(0, len(X))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(30, 20))\n",
    "    ax[0].imshow(X[ix, ..., 0], cmap='Greys_r')\n",
    "    \n",
    "    ax[0].set_title('US-image', c=\"white\" )\n",
    "    ax[0].grid(False)\n",
    "\n",
    "    ax[1].imshow(y[ix].squeeze(), cmap='Greys_r')\n",
    "    ax[1].set_title('Aponeurosis', c=\"white\")\n",
    "    ax[1].grid(False)\n",
    "\n",
    "    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1, cmap=\"Greys_r\")\n",
    "    \n",
    "    ax[2].set_title('Apo-Predicted', c=\"white\")\n",
    "    ax[2].grid(False)\n",
    "    \n",
    "    ax[3].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=0.5, cmap=\"Greys_r\")\n",
    "    \n",
    "    ax[3].set_title('Apo-Picture binary', c=\"white\")\n",
    "    ax[3].grid(False)\n",
    "    \n",
    "    plt.savefig(str(ix)+\"Pred_area.tif\")\n",
    "\n",
    "\n",
    "def conv_block(inputs, num_filters): # found in model_training\n",
    "    x = Conv2D(num_filters, 3, padding = \"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    x = Conv2D(num_filters, 3, padding = \"same\")(x) #NOTE Carla was right, this should be x. This is a bug! \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def decoder_block(inputs, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs) #32\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_vgg16_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    vgg16 = VGG16(include_top=False, weights=\"imagenet\", input_tensor = inputs)\n",
    "    #vgg16.summary()\n",
    "    \n",
    "    \"\"\" Encoder \"\"\"\n",
    "    \n",
    "    # skip connections\n",
    "    s1 = vgg16.get_layer(\"block1_conv2\").output # 256\n",
    "    s2 = vgg16.get_layer(\"block2_conv2\").output # 128\n",
    "    s3 = vgg16.get_layer(\"block3_conv3\").output # 64\n",
    "    s4 = vgg16.get_layer(\"block4_conv3\").output # 32\n",
    "\n",
    "    \"\"\" Bottleneck/Bridge \"\"\"\n",
    "    \n",
    "    b1 = vgg16.get_layer(\"block5_conv3\").output # 16\n",
    "    \n",
    "    \"\"\" Decoder \"\"\"\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "    \n",
    "    \"\"\" Outputs \"\"\"\n",
    "    outputs = Conv2D(1, (1, 1), padding = \"same\", activation=\"sigmoid\")(d4) #binary segmentation\n",
    "    model = Model(inputs, outputs, name = \"VGG16_U-Net\")\n",
    "    return model\n",
    "\n",
    "# Images will be re-scaled\n",
    "im_width = 256\n",
    "im_height = 256\n",
    "border = 5\n",
    "\n",
    "image_directory = \"../data/analyzed_copy/volume\"\n",
    "mask_directory = \"../data/analyzed_copy/mask\"  \n",
    "\n",
    "# list of all images in the path\n",
    "#print(\"Total no. of aponeurosis images = \", len(ids))\n",
    "ids = 0\n",
    "image_dataset = []\n",
    "\n",
    "for patient_path in glob.glob(os.path.join(image_directory, \"Patient*\")):\n",
    "    \n",
    "    for mzp_path in glob.glob(os.path.join(patient_path, \"MZP*\")):\n",
    "        ids = ids + len(os.listdir(mzp_path))\n",
    "        for img_path in glob.glob(os.path.join(mzp_path, \"*.tif\")):\n",
    "            img = cv2.imread(img_path, 1)\n",
    "            img = cv2.resize(img, (256,256))\n",
    "            img = img_to_array(img)\n",
    "            img = img/255.0\n",
    "            image_dataset.append(img)  \n",
    "image_dataset = np.array(image_dataset)\n",
    "\n",
    "print(\"Total no. of aponeurosis images = \", ids)\n",
    "mask_dataset = []\n",
    "\n",
    "for patient_path in glob.glob(os.path.join(mask_directory, \"Patient*\")):\n",
    "    \n",
    "    for mzp_path in glob.glob(os.path.join(patient_path, \"MZP*\")):  \n",
    "        for img_path in glob.glob(os.path.join(mzp_path, \"*.tif\")):\n",
    "            img = cv2.imread(img_path, 0)\n",
    "            img = cv2.resize(img, (256,256))\n",
    "            img = img_to_array(img)\n",
    "            img = img/255.0\n",
    "            mask_dataset.append(img)        \n",
    "mask_dataset = np.array(mask_dataset)\n",
    "\n",
    "# Define some hyperparameters\n",
    "batch_size = 2\n",
    "epochs = 100\n",
    "num_folds = 5\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "\n",
    "#compile the model\n",
    "VGG16_UNet = build_vgg16_unet((256,256,3)) #input_shape is (256, 256, 3)\n",
    "model= VGG16_UNet\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss=\"binary_crossentropy\", metrics= [\"accuracy\", IoU])\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(image_dataset, mask_dataset):\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=20, verbose=1),\n",
    "        ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.0000001, verbose=1),\n",
    "        ModelCheckpoint(f'K-foldno{fold_no}-VGG16-V1-VL-BFRHL-256.keras', verbose=1, save_best_only=True, save_weights_only=False), # Give the model a name (the .h5 part)\n",
    "        CSVLogger(f'K-foldno{fold_no}-VGG16-V1-VL-BFRHL-256.csv', separator=',', append=False)\n",
    "    ]\n",
    "\n",
    "    # # Create a generator\n",
    "    train_datagen = ImageDataGenerator()\n",
    "    val_datagen = ImageDataGenerator()\n",
    "\n",
    "    # Create flow from directory or from arrays\n",
    "    train_generator = train_datagen.flow(image_dataset[train], mask_dataset[train], batch_size=batch_size)\n",
    "    val_generator = val_datagen.flow(image_dataset[test], mask_dataset[test], batch_size=batch_size)\n",
    "    \n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    results = model.fit(train_generator, batch_size=batch_size, epochs=epochs,\n",
    "                        callbacks=callbacks, validation_data=val_generator)\n",
    "    for epoch in range(epochs):\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            batch_size=batch_size,\n",
    "            epochs=1,  # Train one epoch at a time to log metrics continuously\n",
    "            callbacks=callbacks,\n",
    "            validation_data=val_generator\n",
    "        )\n",
    "    \n",
    "    # Extract metrics from history\n",
    "        logs = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": history.history[\"loss\"][-1],\n",
    "            \"train_accuracy\": history.history[\"accuracy\"][-1],\n",
    "            #\"train_iou\": history.history[\"IoU\"][-1],\n",
    "            \"val_loss\": history.history[\"val_loss\"][-1],\n",
    "            \"val_accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "            \"val_iou\": history.history[\"val_IoU\"][-1],\n",
    "            \"learning_rate\": 1e-5\n",
    "        }   \n",
    "        #Log metrics to Wandb\n",
    "        #wandb.log(logs)\n",
    "        #wandb.watch(model, log=\"all\", log_freq=10)\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "    tf.keras.backen.clear_session()\n",
    "#wandb.finish()\n",
    "fold_no = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "from keras_unet_collection.losses import focal_tversky\n",
    "\n",
    "# Set up directories\n",
    "input_directory = 'C:/Users/admin/Documents/DL_Track/Unet_collection/test_images/'  # Directory containing input images\n",
    "output_directory = 'C:/Users/admin/Documents/DL_Track/Unet_collection/output/images'  # Directory where predicted masks will be saved\n",
    "# model = keras.models.load_model('C:/Users/admin/Documents/DL_Track/IFSS_Net/IFSS_Net/IFSS_epoch08_FocalTversky_512.h5')\n",
    "model = keras.models.load_model('C:/Users/admin/Documents/DL_Track/Unet_collection/VGG16-Unet-FocalTversky_epoch100_unaugmented.keras', custom_objects={\"focal_tversky\": focal_tversky, \"IoU\": IoU, \"dice_score\": dice_score})\n",
    "#model = keras.models.load_model('C:/Users/admin/Documents/DL_Track/Models_DL_Track/Final_models/model-fasc-VGG16-BCE-512.h5', custom_objects={\"IoU\": IoU})\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Function to load and preprocess images from a directory\n",
    "def load_and_preprocess_image(image_path, target_size=(512, 512)):\n",
    "    img = load_img(image_path, target_size=target_size)  # Load the image with target size\n",
    "    img_array = img_to_array(img)  # Convert the image to a numpy array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = img_array / 255.0  # Normalize the image to [0, 1] range\n",
    "    return img_array\n",
    "\n",
    "# Function to save predicted masks with Pillow\n",
    "def save_predicted_mask(predicted_mask, image_name):\n",
    "    # Apply a threshold to make the mask binary (0 or 1)\n",
    "    binary_mask = (predicted_mask >= 0.05).astype(np.uint8)  # Apply threshold and convert to 0 and 1\n",
    "    \n",
    "    # Rescale the binary mask to [0, 255] for saving as an image\n",
    "    binary_mask = binary_mask * 255\n",
    "    \n",
    "    # Convert the numpy array to a Pillow image\n",
    "    binary_mask_image = Image.fromarray(np.squeeze(binary_mask))\n",
    "    \n",
    "    # Save the image using Pillow\n",
    "    output_path = os.path.join(output_directory, os.path.splitext(image_name)[0] + '.tif')  # Save as .tif\n",
    "    binary_mask_image.save(output_path)\n",
    "\n",
    "# Load images, predict masks, and save results\n",
    "for image_name in os.listdir(input_directory):\n",
    "    if image_name.endswith('.tif') or image_name.endswith('.png'):  # Change to your file extension\n",
    "        image_path = os.path.join(input_directory, image_name)\n",
    "        \n",
    "        # Load and preprocess the image\n",
    "        input_image = load_and_preprocess_image(image_path)\n",
    "        \n",
    "        # Use the model to predict the mask\n",
    "        predicted_mask = model.predict(input_image)[0]  # [0] to remove batch dimension\n",
    "        \n",
    "        # Save the predicted mask\n",
    "        save_predicted_mask(predicted_mask, image_name)\n",
    "\n",
    "print(\"Predicted masks have been saved to\", output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
