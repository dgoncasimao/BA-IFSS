{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16-UNet with DL-Kfold (build_vgg16_unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of aponeurosis images =  314\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 178\u001b[0m\n\u001b[0;32m    176\u001b[0m         mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(mask, (\u001b[38;5;241m256\u001b[39m,\u001b[38;5;241m256\u001b[39m))\n\u001b[0;32m    177\u001b[0m         mask \u001b[38;5;241m=\u001b[39m img_to_array(mask)\n\u001b[1;32m--> 178\u001b[0m         mask \u001b[38;5;241m=\u001b[39m \u001b[43mmask\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m255.0\u001b[39;49m\n\u001b[0;32m    179\u001b[0m         mask_dataset\u001b[38;5;241m.\u001b[39mappend(mask)        \n\u001b[0;32m    180\u001b[0m mask_dataset \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(mask_dataset)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Model\n",
    "from keras_unet_collection.losses import focal_tversky\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.applications import VGG16 \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "\n",
    "def IoU(y_true, y_pred, dtype=tf.float32):\n",
    "    y_pred = tf.cast(y_pred, dtype)\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "\n",
    "    y_pred = tf.squeeze(y_pred)\n",
    "    y_true = tf.squeeze(y_true)\n",
    "\n",
    "    y_true_pos = tf.reshape(y_true, [-1])\n",
    "    y_pred_pos = tf.reshape(y_pred, [-1])\n",
    "\n",
    "    area_intersect = tf.reduce_sum(tf.multiply(y_true_pos, y_pred_pos))\n",
    "    \n",
    "    area_true = tf.reduce_sum(y_true_pos)\n",
    "    area_pred = tf.reduce_sum(y_pred_pos)\n",
    "    area_union = area_true + area_pred - area_intersect\n",
    "    \n",
    "    # Return the IoU score\n",
    "    return tf.math.divide_no_nan(area_intersect, area_union)\n",
    "\n",
    "def dice_score(y_true, y_pred, smooth=1):\n",
    "    \n",
    "    # Flatten\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def tversky(y_true, y_pred, smooth=1, alpha=0.7):\n",
    "    y_true_pos = K.flatten(y_true)\n",
    "    y_pred_pos = K.flatten(y_pred)\n",
    "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n",
    "    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n",
    "    return (true_pos + smooth) / (true_pos + alpha * false_neg + (1 - alpha) * false_pos + smooth)\n",
    "\n",
    "\n",
    "def tversky_loss(y_true, y_pred):\n",
    "    return 1 - tversky(y_true, y_pred)\n",
    "\n",
    "\n",
    "def focal_tversky_loss(y_true, y_pred, gamma=0.75):\n",
    "    tv = tversky(y_true, y_pred)\n",
    "    return K.pow((1 - tv), gamma)\n",
    "\n",
    "\n",
    "# Plot sample of model prediction\n",
    "def plot_sample(X, y, preds, binary_preds, ix=None):\n",
    "    if ix is None:\n",
    "        ix = random.randint(0, len(X))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(30, 20))\n",
    "    ax[0].imshow(X[ix, ..., 0], cmap='Greys_r')\n",
    "    \n",
    "    ax[0].set_title('US-image', c=\"white\" )\n",
    "    ax[0].grid(False)\n",
    "\n",
    "    ax[1].imshow(y[ix].squeeze(), cmap='Greys_r')\n",
    "    ax[1].set_title('Aponeurosis', c=\"white\")\n",
    "    ax[1].grid(False)\n",
    "\n",
    "    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1, cmap=\"Greys_r\")\n",
    "    \n",
    "    ax[2].set_title('Apo-Predicted', c=\"white\")\n",
    "    ax[2].grid(False)\n",
    "    \n",
    "    ax[3].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=0.5, cmap=\"Greys_r\")\n",
    "    \n",
    "    ax[3].set_title('Apo-Picture binary', c=\"white\")\n",
    "    ax[3].grid(False)\n",
    "    \n",
    "    plt.savefig(str(ix)+\"Pred_area.tif\")\n",
    "\n",
    "\n",
    "def conv_block(inputs, num_filters): # found in model_training\n",
    "    x = Conv2D(num_filters, 3, padding = \"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    x = Conv2D(num_filters, 3, padding = \"same\")(x) #NOTE Carla was right, this should be x. This is a bug! \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def decoder_block(inputs, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs) #32\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_vgg16_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    vgg16 = VGG16(include_top=False, weights=\"imagenet\", input_tensor = inputs)\n",
    "    #vgg16.summary()\n",
    "    \n",
    "    \"\"\" Encoder \"\"\"\n",
    "    \n",
    "    # skip connections\n",
    "    s1 = vgg16.get_layer(\"block1_conv2\").output # 256\n",
    "    s2 = vgg16.get_layer(\"block2_conv2\").output # 128\n",
    "    s3 = vgg16.get_layer(\"block3_conv3\").output # 64\n",
    "    s4 = vgg16.get_layer(\"block4_conv3\").output # 32\n",
    "\n",
    "    \"\"\" Bottleneck/Bridge \"\"\"\n",
    "    \n",
    "    b1 = vgg16.get_layer(\"block5_conv3\").output # 16\n",
    "    \n",
    "    \"\"\" Decoder \"\"\"\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "    \n",
    "    \"\"\" Outputs \"\"\"\n",
    "    outputs = Conv2D(1, (1, 1), padding = \"same\", activation=\"sigmoid\")(d4) #binary segmentation\n",
    "    model = Model(inputs, outputs, name = \"VGG16_U-Net\")\n",
    "    return model\n",
    "\n",
    "# Images will be re-scaled\n",
    "im_width = 256\n",
    "im_height = 256\n",
    "border = 5\n",
    "\n",
    "image_directory = \"C:/Users/diego/Bac Sport and Computer Science/BA-arbeit/RepoBA/BA-IFSS/data/analyzed_data/008/MZP1/volume\"\n",
    "mask_directory = \"C:/Users/diego/Bac Sport and Computer Science/BA-arbeit/RepoBA/BA-IFSS/data/analyzed_data/008/MZP1/mask\"  \n",
    "\n",
    "# list of all images in the path\n",
    "ids = os.listdir(image_directory)\n",
    "print(\"Total no. of aponeurosis images = \", len(ids))\n",
    "\n",
    "image_dataset = []\n",
    "for path in glob.glob(image_directory):\n",
    "    for img_path in glob.glob(os.path.join(path, \"*.tif\")):\n",
    "        img = cv2.imread(img_path, 1)\n",
    "        img = cv2.resize(img, (256,256))\n",
    "        img = img_to_array(img)\n",
    "        img = img/255.0\n",
    "        image_dataset.append(img)  \n",
    "image_dataset = np.array(image_dataset)\n",
    "\n",
    "mask_dataset = []\n",
    "for path in glob.glob(mask_directory):\n",
    "    for mask_path in glob.glob(os.path.join(path, \"*.tif\")):\n",
    "        mask = cv2.imread(mask_path, 0)\n",
    "        mask = cv2.resize(mask, (256,256))\n",
    "        mask = img_to_array(mask)\n",
    "        mask = mask/255.0\n",
    "        mask_dataset.append(mask)        \n",
    "mask_dataset = np.array(mask_dataset)\n",
    "\n",
    "# Define some hyperparameters\n",
    "batch_size = 2\n",
    "epochs = 100\n",
    "num_folds = 5\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "\n",
    "#compile the model\n",
    "VGG16_UNet = build_vgg16_unet((256,256,3)) #input_shape is (256, 256, 3)\n",
    "model= VGG16_UNet\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss=\"binary_crossentropy\", metrics= [\"accuracy\", IoU])\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(image_dataset, mask_dataset):\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=20, verbose=1),\n",
    "        ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.0000001, verbose=1),\n",
    "        ModelCheckpoint(f'K-foldno{fold_no}-VGG16-V1-VL-BFRHL-256.keras', verbose=1, save_best_only=True, save_weights_only=False), # Give the model a name (the .h5 part)\n",
    "        CSVLogger(f'K-foldno{fold_no}-VGG16-V1-VL-BFRHL-256.csv', separator=',', append=False)\n",
    "    ]\n",
    "\n",
    "    # # Create a generator\n",
    "    train_datagen = ImageDataGenerator()\n",
    "    val_datagen = ImageDataGenerator()\n",
    "\n",
    "    # Create flow from directory or from arrays\n",
    "    train_generator = train_datagen.flow(image_dataset[train], mask_dataset[train], batch_size=batch_size)\n",
    "    val_generator = val_datagen.flow(image_dataset[test], mask_dataset[test], batch_size=batch_size)\n",
    "    \n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    results = model.fit(train_generator, batch_size=batch_size, epochs=epochs,\n",
    "                        callbacks=callbacks, validation_data=val_generator)\n",
    "\n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "    clear_session()\n",
    "\n",
    "fold_no = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepACSA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
