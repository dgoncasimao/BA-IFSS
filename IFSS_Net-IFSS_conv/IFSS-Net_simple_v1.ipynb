{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv3D, MaxPooling3D, Dropout, ConvLSTM2D\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Dropout, ConvLSTM2D\n",
    "from tensorflow.keras import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from data_utilities_v2 import *\n",
    "from IFSSNet_utilities_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape_x, input_shape_y, num_classes, keep_prob_skip=0.2):   \n",
    "    x_target = tf.keras.Input(shape=input_shape_x, name='x_target')\n",
    "    y_estimated = tf.keras.Input(shape=input_shape_y, name='y_estimated')\n",
    "    print(x_target)\n",
    "    print(y_estimated)\n",
    "\n",
    "    ################# Layer 1\n",
    "    Layer_1 = Conv3DBlock(x_target, n_filters=30, kernel_size=(3, 3, 3), stride=(1, 1, 1), activation_fn=None)\n",
    "    Layer_1 = MaxPooling3D(pool_size=(3, 3, 3), strides=(1, 2, 2), padding='same', name='Layer_1p')(Layer_1)\n",
    "    Layer_1 = AtrousSpatialPyramidPoolingModule_3D(Layer_1, depth=6)\n",
    "    Layer_1 = Dropout(rate=1 - keep_prob_skip)(Layer_1)\n",
    "    print(Layer_1)\n",
    "\n",
    "    ################ Layer 2\n",
    "    Layer_2 = Conv3DBlock(Layer_1, 30, kernel_size=(3, 3, 3), stride=(1, 1, 1), activation_fn=None)\n",
    "    Layer_2 = MaxPooling3D(pool_size=(3, 3, 3), strides=(1, 2, 2), padding='same', name='Layer_2p')(Layer_2)\n",
    "    Layer_2 = AtrousSpatialPyramidPoolingModule_3D(Layer_2, depth=6)\n",
    "    Layer_2 = Dropout(rate=1 - keep_prob_skip)(Layer_2)\n",
    "    print(Layer_2)\n",
    "\n",
    "    ############### Layer 3\n",
    "    Layer_3 = Conv3DBlock(Layer_2, 60, kernel_size=(3, 3, 3), stride=(1, 1, 1), activation_fn=None)\n",
    "    Layer_3 = MaxPooling3D(pool_size=(3, 3, 3), strides=(1, 2, 2), padding='same', name='Layer_3p')(Layer_3)\n",
    "    Layer_3 = AtrousSpatialPyramidPoolingModule_3D_rate_11(Layer_3, depth=12)\n",
    "    Layer_3 = Dropout(rate=1 - keep_prob_skip)(Layer_3)\n",
    "    print(Layer_3)\n",
    "    \n",
    "    ############## Layer 4\n",
    "    Layer_4 = Conv3DBlock(Layer_3, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), activation_fn=None)\n",
    "    Layer_4 = MaxPooling3D(pool_size=(3, 3, 3), strides=(1, 2, 2), padding='same', name='Layer_4p')(Layer_4)\n",
    "    Layer_4 = AtrousSpatialPyramidPoolingModule_3D_rate_9(Layer_4, depth=24)\n",
    "    Layer_4 = Dropout(rate=1 - keep_prob_skip)(Layer_4)\n",
    "    print(Layer_4)\n",
    "    \n",
    "    ############## Layer 5\n",
    "\n",
    "    Layer_5 = Conv3DBlock(Layer_4, 120, kernel_size=(3, 3, 3), stride=(1, 1, 1), activation_fn=None)\n",
    "    Layer_5 = MaxPooling3D(pool_size=(3, 3, 3), strides=(1, 2, 2), padding='same', name='Layer_5p')(Layer_5)\n",
    "    Layer_5 = AtrousSpatialPyramidPoolingModule_3D_rate_9(Layer_5, depth=24)\n",
    "    print(Layer_5)                                                      \n",
    "    \n",
    "    # # Encoder Stream for Estimated Predictions (reuse features from x)\n",
    "\n",
    "    ################# Layer 1\n",
    "    Layer_1y = Conv3DBlock(y_estimated, 30, kernel_size=(3,3,3), stride=(1,1,1), activation_fn=None)\n",
    "    Layer_1y = MaxPooling3D(pool_size=(3, 3, 3), strides=(1, 2, 2), padding='same')(Layer_1y)\n",
    "    Layer_1y = AtrousSpatialPyramidPoolingModule_3D(Layer_1y, depth=6)\n",
    "    Layer_1y = Dropout(rate=1 - keep_prob_skip)(Layer_1y)\n",
    "    print(Layer_1y)\n",
    "\n",
    "    ############### Layer 2\n",
    "    Layer_2y = Conv3DBlock(Layer_1y, 30, kernel_size=(3,3,3), stride=(1,1,1), activation_fn=None)\n",
    "    Layer_2y = MaxPooling3D(pool_size=(3, 3, 3), strides=(1, 2, 2), padding='same')(Layer_2y)\n",
    "    Layer_2y = AtrousSpatialPyramidPoolingModule_3D(Layer_2y, depth=6)\n",
    "    Layer_2y = Dropout(rate=1 - keep_prob_skip)(Layer_2y)\n",
    "    print(Layer_2y)\n",
    "\n",
    "    ############## Layer 3\n",
    "    Layer_3y = Conv3DBlock(Layer_2y, 60, kernel_size=(3,3,3), stride=(1,1,1), activation_fn=None)\n",
    "    Layer_3y = MaxPooling3D(pool_size=(3, 3, 3), strides=(1, 2, 2), padding='same')(Layer_3y)\n",
    "    Layer_3y = AtrousSpatialPyramidPoolingModule_3D_rate_11(Layer_3y, depth=12)\n",
    "    Layer_3y = Dropout(rate=1 - keep_prob_skip)(Layer_3y)\n",
    "    print(Layer_3y)\n",
    "    \n",
    "    ############## Layer 4\n",
    "    Layer_4y = Conv3DBlock(Layer_3y, 120, kernel_size=(3,3,3), stride=(1,1,1), activation_fn=None)\n",
    "    Layer_4y = MaxPooling3D(pool_size=(3, 3, 3), strides=(1, 2, 2), padding='same')(Layer_4y)\n",
    "    Layer_4y = AtrousSpatialPyramidPoolingModule_3D_rate_9(Layer_4y, depth=24)\n",
    "    Layer_4y = Dropout(rate=1 - keep_prob_skip)(Layer_4y)\n",
    "    print(Layer_4y)\n",
    "    \n",
    "    ############# Layer 5\n",
    "    Layer_5y = Conv3DBlock(Layer_4y, 120, kernel_size=(3,3,3), stride=(1,1,1), activation_fn=None)\n",
    "    Layer_5y = MaxPooling3D(pool_size=(3, 3, 3), strides=(1, 2, 2), padding='same')(Layer_5y)\n",
    "    Layer_5y = AtrousSpatialPyramidPoolingModule_3D_rate_9(Layer_5y, depth=24)\n",
    "    print(Layer_5y)\n",
    "    \n",
    "    # # Fusion and SpatioTemporal Correlations\n",
    "\n",
    "    Fused_x_y = FeatureFusionModule(Layer_5, Layer_5y, 120)\n",
    "    print(Fused_x_y)\n",
    "\n",
    "    BiSpatioTemporal_x_y_F = ConvLSTM2D(filters=120, kernel_size=(1, 1), padding='same', return_sequences=True, \n",
    "                                        go_backwards=False, kernel_initializer='he_normal',\n",
    "                                        recurrent_dropout=0.3, activation=tf.nn.tanh)(Fused_x_y)\n",
    "    print(BiSpatioTemporal_x_y_F)\n",
    "\n",
    "    Fused_x_y_Reversed = Lambda(lambda x: tf.reverse(x, axis=[1]))(Fused_x_y)\n",
    "    print(Fused_x_y_Reversed)\n",
    "\n",
    "    BiSpatioTemporal_x_y_B = ConvLSTM2D(filters=120, kernel_size=(1, 1), padding='same', return_sequences=True, \n",
    "                                        go_backwards=False, kernel_initializer='he_normal',\n",
    "                                        recurrent_dropout=0.3, activation=tf.nn.tanh)(Fused_x_y_Reversed)\n",
    "    print(BiSpatioTemporal_x_y_B)\n",
    "\n",
    "    # Combine forward and backward passes\n",
    "    BiSpatioTemporal_x_y = Add()([BiSpatioTemporal_x_y_F, Lambda(lambda x: tf.reverse(x, axis=[1]))(BiSpatioTemporal_x_y_B)])\n",
    "    print(BiSpatioTemporal_x_y)\n",
    "\n",
    "    # # Build the Decoder\n",
    "\n",
    "    # Building the Decoder Layers\n",
    "\n",
    "    ########## Layer 6\n",
    "    Layer_6 = Conv3DBlockTranspose(BiSpatioTemporal_x_y, 120, kernel_size=[3,3,3], stride=[1,1,1], activation_fn=None)\n",
    "    Layer_6 = Conv3DBlock(Layer_6, 120, kernel_size=[3,3,3], stride=[1,1,1], activation_fn=None)\n",
    "    Layer_6 = FeatureFusionModule(input_1=Layer_6, input_2=BiSpatioTemporal_x_y, n_filters=120)\n",
    "    Layer_6 = unpool_3D(Layer_6)\n",
    "    Layer_6 = layers.Dropout(1 - keep_prob_skip)(Layer_6)\n",
    "    print(Layer_6)\n",
    "    \n",
    "    ######### Layer 7\n",
    "    Layer_7 = Conv3DBlockTranspose(Layer_6, 120, kernel_size=[3,3,3], stride=[1,1,1], activation_fn=None)\n",
    "    Layer_7 = Conv3DBlock(Layer_7, 120, kernel_size=[3,3,3], stride=[1,1,1], activation_fn=None)\n",
    "    Layer_7 = FeatureFusionModule(input_1=Layer_7, input_2=Layer_4, n_filters=120)\n",
    "    Layer_7 = unpool_3D(Layer_7)\n",
    "    Layer_7 = layers.Dropout(1 - keep_prob_skip)(Layer_7)\n",
    "    print(Layer_7)\n",
    "    \n",
    "    ######### Layer 8\n",
    "    Layer_8 = Conv3DBlockTranspose(Layer_7, 60, kernel_size=[3,3,3], stride=[1,1,1], activation_fn=None)\n",
    "    Layer_8 = Conv3DBlock(Layer_8, 60, kernel_size=[3,3,3], stride=[1,1,1], activation_fn=None)\n",
    "    Layer_8 = FeatureFusionModule(input_1=Layer_8, input_2=Layer_3, n_filters=60)\n",
    "    Layer_8 = unpool_3D(Layer_8)\n",
    "    Layer_8 = layers.Dropout(1 - keep_prob_skip)(Layer_8)\n",
    "    print(Layer_8)\n",
    "        \n",
    "    ######## Layer 9\n",
    "    Layer_9 = Conv3DBlockTranspose(Layer_8, 60, kernel_size=[3,3,3], stride=[1,1,1], activation_fn=None)\n",
    "    Layer_9 = Conv3DBlock(Layer_9, 60, kernel_size=[3,3,3], stride=[1,1,1], activation_fn=None)\n",
    "    Layer_9 = FeatureFusionModule(input_1=Layer_9, input_2=Layer_2, n_filters=60)\n",
    "    Layer_9 = unpool_3D(Layer_9)\n",
    "    Layer_9 = layers.Dropout(1 - keep_prob_skip)(Layer_9)\n",
    "    print(Layer_9)\n",
    "    \n",
    "    ######## Layer 10\n",
    "    Layer_10 = Conv3DBlockTranspose(Layer_9, 16, kernel_size=[3,3,3], stride=[1,1,1], activation_fn=None)\n",
    "    Layer_10 = Conv3DBlock(Layer_10, 16, kernel_size=[3,3,3], stride=[1,1,1], activation_fn=None)\n",
    "    Layer_10 = FeatureFusionModule(input_1=Layer_10, input_2=Layer_1, n_filters=16)\n",
    "    Layer_10 = unpool_3D(Layer_10)\n",
    "    Layer_10 = layers.Dropout(1 - keep_prob_skip)(Layer_10)\n",
    "    print(Layer_10)\n",
    "    \n",
    "    ######## Layer 11\n",
    "    Layer_11 = Conv3DBlockTranspose(Layer_10, 8, kernel_size=[3,3,3], stride=[1,1,1], activation_fn=None)\n",
    "    Layer_11 = Conv3DBlock(Layer_11, 8, kernel_size=[1,1,1], stride=[1,1,1], activation_fn=None)\n",
    "    Layer_11 = layers.Dropout(1 - keep_prob_skip)(Layer_11)  \n",
    "    print(Layer_11)     \n",
    "\n",
    "    net_output_256_logits = Conv3D(num_classes, kernel_size=(1,1,1), activation=tf.nn.relu)(Layer_11)\n",
    "    print(net_output_256_logits)\n",
    "\n",
    "    net_output_256 = pixel_wise_softmax(net_output_256_logits)\n",
    "    print(net_output_256)\n",
    "\n",
    "    model = Model(inputs=[x_target, y_estimated], outputs= net_output_256)\n",
    "    return model\n",
    "\n",
    "time_step = None # whatever the depth of the volume, we use a sliding window of T\n",
    "H=512\n",
    "W=512\n",
    "C = 1 # number of input channels\n",
    "num_classes = 2 # related to SOl or GL or GM muscles\n",
    "n_class = 2\n",
    "\n",
    "input_shape_x = (time_step, H, W, C)\n",
    "input_shape_y = (time_step, H, W, num_classes)\n",
    "model = create_model(input_shape_x, input_shape_y, num_classes)\n",
    "model.compile(optimizer='adam', loss='tversky', metrics=['accuracy']) # paper loss = Tversky loss\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_directory = 'C:/Users/carla/Documents/Master_Thesis/Example_Images/FALLMUD/NeilCronin/training_fascicle_masks_small/'\n",
    "\n",
    "image_directory = 'C:/Users/carla/Documents/Master_Thesis/Example_Images/FALLMUD/NeilCronin/training_images_small/'\n",
    "\n",
    "sub_vol_size = 5\n",
    "last_ind = sub_vol_size-1\n",
    "\n",
    "image_dataset = []\n",
    "for path in glob.glob(image_directory):\n",
    "    for img_path in glob.glob(os.path.join(path, \"*.tif\")):\n",
    "        img = cv2.imread(img_path, 1)\n",
    "        img = cv2.resize(img, (512,512))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = img.reshape((img.shape[0], img.shape[1], 1))\n",
    "        img = np.array(img)\n",
    "        img = img/255.0\n",
    "        image_dataset.append(img)  \n",
    "image_dataset = np.array(image_dataset)\n",
    "\n",
    "stacked_image_dataset = []\n",
    "for i in range(len(image_dataset)-last_ind):\n",
    "    stacked_images = tf.stack([image_dataset[i], image_dataset[i+1], image_dataset[i+2]], axis=0)\n",
    "    stacked_image_dataset.append(stacked_images)\n",
    "stacked_image_dataset = np.array(stacked_image_dataset)\n",
    "\n",
    "mask_dataset = []\n",
    "for path in glob.glob(mask_directory):\n",
    "    for mask_path in glob.glob(os.path.join(path, \"*.tif\")):\n",
    "        mask = cv2.imread(mask_path, 0)\n",
    "        mask = cv2.resize(mask, (512,512))\n",
    "        mask = np.stack((mask, mask), axis=-1)\n",
    "        mask = np.array(mask)\n",
    "        mask = mask/255.0\n",
    "        mask_dataset.append(mask)        \n",
    "mask_dataset = np.array(mask_dataset)\n",
    "\n",
    "stacked_mask_dataset = []\n",
    "for i in range(len(mask_dataset)-last_ind):\n",
    "    stacked_mask = tf.stack([mask_dataset[i], mask_dataset[i+1], mask_dataset[i+2]], axis=0)\n",
    "    stacked_mask_dataset.append(stacked_mask)\n",
    "stacked_mask_dataset = np.array(stacked_mask_dataset)\n",
    "\n",
    "x_train = stacked_image_dataset\n",
    "y_train = stacked_mask_dataset\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "checkpoint = ModelCheckpoint(f'K-IFSS-Net-simple.keras', verbose=1, save_best_only=True, save_weights_only=False)\n",
    "early_stopping = EarlyStopping(patience=8, verbose=1)\n",
    "\n",
    "batch_size = 2\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([x_train, y_train], y_train,\n",
    "                    validation_data=([x_val, y_val], y_val),\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[checkpoint, early_stopping])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
